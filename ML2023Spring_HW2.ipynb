{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYlaRwNu7ojq"
      },
      "source": [
        "# **Homework 2: Phoneme Classification**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7DRC5V7_8A5"
      },
      "source": [
        "Objectives:\n",
        "* Solve a classification problem with deep neural networks (DNNs).\n",
        "* Understand recursive neural networks (RNNs).\n",
        "\n",
        "If you have any questions, please contact the TAs via TA hours, NTU COOL, or email to mlta-2023-spring@googlegroups.com"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVUGfWTo7_Oj"
      },
      "source": [
        "# Download Data\n",
        "Download data from google drive, then unzip it.\n",
        "\n",
        "You should have\n",
        "- `libriphone/train_split.txt`: training metadata\n",
        "- `libriphone/train_labels`: training labels\n",
        "- `libriphone/test_split.txt`: testing metadata\n",
        "- `libriphone/feat/train/*.pt`: training feature\n",
        "- `libriphone/feat/test/*.pt`:  testing feature\n",
        "\n",
        "after running the following block.\n",
        "\n",
        "> **Notes: if the google drive link is dead, you can download the data directly from [Kaggle](https://www.kaggle.com/c/ml2023spring-hw2/data) and upload it to the workspace.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OzkiMEcC3Foq"
      },
      "outputs": [],
      "source": [
        "# #!pip install --upgrade gdown\n",
        "\n",
        "# # Main link\n",
        "# !gdown --id '1N1eVIDe9hKM5uiNRGmifBlwSDGiVXPJe' --output libriphone.zip\n",
        "# # !gdown --id '1qzCRnywKh30mTbWUEjXuNT2isOCAPdO1' --output libriphone.zip\n",
        "\n",
        "# !unzip -q libriphone.zip\n",
        "# !ls libriphone"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pADUiYODJE1O"
      },
      "source": [
        "# Some Utility Functions\n",
        "**Fixes random number generator seeds for reproducibility.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "BsZKgBZQJjaE"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import random\n",
        "\n",
        "def same_seeds(seed):\n",
        "    random.seed(seed) \n",
        "    np.random.seed(seed)  \n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed) \n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_L_4anls8Drv"
      },
      "source": [
        "**Helper functions to pre-process the training data from raw MFCC features of each utterance.**\n",
        "\n",
        "A phoneme may span several frames and is dependent to past and future frames. \\\n",
        "Hence we concatenate neighboring phonemes for training to achieve higher accuracy. The **concat_feat** function concatenates past and future k frames (total 2k+1 = n frames), and we predict the center frame.\n",
        "\n",
        "Feel free to modify the data preprocess functions, but **do not drop any frame** (if you modify the functions, remember to check that the number of frames are the same as mentioned in the slides)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "IJjLT8em-y9G"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# import torch\n",
        "# from tqdm import tqdm\n",
        "\n",
        "# def load_feat(path):\n",
        "#     feat = torch.load(path)\n",
        "#     return feat\n",
        "\n",
        "# def shift(x, n):\n",
        "#     if n < 0:\n",
        "#         #md，看见下面n是负的脑子没转过弯，是因为判断了n小于0，所以取负号变成正的\n",
        "#         left = x[0].repeat(-n, 1)\n",
        "#         right = x[:n]\n",
        "#     elif n > 0:\n",
        "#         right = x[-1].repeat(n, 1)\n",
        "#         left = x[n:]\n",
        "#     else:\n",
        "#         return x\n",
        "\n",
        "#     return torch.cat((left, right), dim=0)\n",
        "\n",
        "# def concat_feat(x, concat_n):\n",
        "#     assert concat_n % 2 == 1 # n must be odd\n",
        "#     if concat_n < 2:\n",
        "#         return x\n",
        "#     seq_len, feature_dim = x.size(0), x.size(1)\n",
        "#     x = x.repeat(1, concat_n) \n",
        "#     x = x.view(seq_len, concat_n, feature_dim).permute(1, 0, 2) # concat_n, seq_len, feature_dim\n",
        "#     mid = (concat_n // 2)\n",
        "#     for r_idx in range(1, mid+1):\n",
        "#         x[mid + r_idx, :] = shift(x[mid + r_idx], r_idx)\n",
        "#         x[mid - r_idx, :] = shift(x[mid - r_idx], -r_idx)\n",
        "\n",
        "#     return x.permute(1, 0, 2).view(seq_len, concat_n * feature_dim)\n",
        "\n",
        "# def preprocess_data(split, feat_dir, phone_path, concat_nframes, train_ratio=0.8):\n",
        "#     class_num = 41 # NOTE: pre-computed, should not need change\n",
        "\n",
        "#     if split == 'train' or split == 'val':\n",
        "#         mode = 'train'\n",
        "#     elif split == 'test':\n",
        "#         mode = 'test'\n",
        "#     else:\n",
        "#         raise ValueError('Invalid \\'split\\' argument for dataset: PhoneDataset!')\n",
        "\n",
        "#     label_dict = {}\n",
        "#     if mode == 'train':\n",
        "#         for line in open(os.path.join(phone_path, f'{mode}_labels.txt')).readlines():\n",
        "#             line = line.strip('\\n').split(' ')\n",
        "#             label_dict[line[0]] = [int(p) for p in line[1:]]\n",
        "        \n",
        "#         # split training and validation data\n",
        "#         usage_list = open(os.path.join(phone_path, 'train_split.txt')).readlines()\n",
        "#         random.shuffle(usage_list)\n",
        "#         train_len = int(len(usage_list) * train_ratio)\n",
        "#         usage_list = usage_list[:train_len] if split == 'train' else usage_list[train_len:]\n",
        "\n",
        "#     elif mode == 'test':\n",
        "#         usage_list = open(os.path.join(phone_path, 'test_split.txt')).readlines()\n",
        "\n",
        "#     usage_list = [line.strip('\\n') for line in usage_list]\n",
        "#     print('[Dataset] - # phone classes: ' + str(class_num) + ', number of utterances for ' + split + ': ' + str(len(usage_list)))\n",
        "\n",
        "#     max_len = 3000000\n",
        "#     X = torch.empty(max_len, 39 * concat_nframes)\n",
        "#     if mode == 'train':\n",
        "#         y = torch.empty(max_len, dtype=torch.long)\n",
        "\n",
        "#     idx = 0\n",
        "#     for i, fname in tqdm(enumerate(usage_list)):\n",
        "#         feat = load_feat(os.path.join(feat_dir, mode, f'{fname}.pt'))\n",
        "#         cur_len = len(feat)\n",
        "#         feat = concat_feat(feat, concat_nframes)\n",
        "#         if mode == 'train':\n",
        "#           label = torch.LongTensor(label_dict[fname])\n",
        "\n",
        "#         X[idx: idx + cur_len, :] = feat\n",
        "#         if mode == 'train':\n",
        "#           y[idx: idx + cur_len] = label\n",
        "\n",
        "#         idx += cur_len\n",
        "\n",
        "#     X = X[:idx, :]\n",
        "#     if mode == 'train':\n",
        "#       y = y[:idx]\n",
        "\n",
        "#     print(f'[INFO] {split} set')\n",
        "#     print(X.shape)\n",
        "#     if mode == 'train':\n",
        "#       print(y.shape)\n",
        "#       return X, y\n",
        "#     else:\n",
        "#       return X\n",
        "\n",
        "import os\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "def load_feat(path):\n",
        "    feat = torch.load(path)\n",
        "    return feat\n",
        "\n",
        "def shift(x, n):\n",
        "    if n < 0:\n",
        "        left = x[0].repeat(-n, 1)\n",
        "        right = x[:n]\n",
        "    elif n > 0:\n",
        "        right = x[-1].repeat(n, 1)\n",
        "        left = x[n:]\n",
        "    else:\n",
        "        return x\n",
        "\n",
        "    return torch.cat((left, right), dim=0)\n",
        "\n",
        "# def concat_feat(x, concat_n):\n",
        "#     assert concat_n % 2 == 1 # n must be odd\n",
        "#     if concat_n < 2:\n",
        "#         return x\n",
        "#     seq_len, feature_dim = x.size(0), x.size(1)\n",
        "#     x = x.repeat(1, concat_n) \n",
        "#     x = x.view(seq_len, concat_n, feature_dim).permute(1, 0, 2) # concat_n, seq_len, feature_dim\n",
        "#     mid = (concat_n // 2)\n",
        "#     for r_idx in range(1, mid+1):\n",
        "#         x[mid + r_idx, :] = shift(x[mid + r_idx], r_idx)\n",
        "#         x[mid - r_idx, :] = shift(x[mid - r_idx], -r_idx)\n",
        "\n",
        "#     return x.permute(1, 0, 2).view(seq_len, concat_n * feature_dim)\n",
        "#deepseek优化向量拼接\n",
        "def concat_feat(x, concat_n):\n",
        "    assert concat_n % 2 == 1 # n must be odd\n",
        "    if concat_n < 2: \n",
        "        return x\n",
        "    \n",
        "    seq_len, feat_dim = x.shape\n",
        "    mid = concat_n // 2\n",
        "    device = x.device\n",
        "    \n",
        "    # 创建位移索引模板\n",
        "    indices = torch.arange(seq_len, device=device)[:, None] + torch.arange(-mid, mid+1, device=device)\n",
        "    indices = torch.clamp(indices, 0, seq_len-1)  # 边界限制\n",
        "    \n",
        "    # 通过索引直接获取拼接特征\n",
        "    stacked = x[indices.view(-1)].view(seq_len, concat_n, feat_dim)\n",
        "    return stacked.view(seq_len, -1)\n",
        "\n",
        "def preprocess_data(split, feat_dir, phone_path, concat_nframes, train_ratio=0.8):\n",
        "    class_num = 41 # NOTE: pre-computed, should not need change\n",
        "\n",
        "    if split == 'train' or split == 'val':\n",
        "        mode = 'train'\n",
        "    elif split == 'test':\n",
        "        mode = 'test'\n",
        "    else:\n",
        "        raise ValueError('Invalid \\'split\\' argument for dataset: PhoneDataset!')\n",
        "\n",
        "    label_dict = {}\n",
        "    if mode == 'train':\n",
        "        for line in open(os.path.join(phone_path, f'{mode}_labels.txt')).readlines():\n",
        "            line = line.strip('\\n').split(' ')\n",
        "            label_dict[line[0]] = [int(p) for p in line[1:]]\n",
        "        \n",
        "        # split training and validation data\n",
        "        usage_list = open(os.path.join(phone_path, 'train_split.txt')).readlines()\n",
        "        random.shuffle(usage_list)\n",
        "        train_len = int(len(usage_list) * train_ratio)\n",
        "        train_list = usage_list[:train_len]\n",
        "        val_list = usage_list[train_len:]\n",
        "\n",
        "    elif mode == 'test':\n",
        "        test_list = open(os.path.join(phone_path, 'test_split.txt')).readlines()\n",
        "\n",
        "    # 略微魔改了一下关于数据划分的代码，避免出现训练验证集交叉的可能\n",
        "    def transform_data(usage_list, split):\n",
        "        usage_list = [line.strip('\\n') for line in usage_list]\n",
        "        print('[Dataset] - # phone classes: ' + str(class_num) + ', number of utterances for ' + split + ': ' + str(len(usage_list)))\n",
        "\n",
        "        max_len = 3000000\n",
        "        X = torch.empty(max_len, 39 * concat_nframes)\n",
        "        if mode == 'train':\n",
        "            y = torch.empty(max_len, dtype=torch.long)\n",
        "\n",
        "        idx = 0\n",
        "        for i, fname in tqdm(enumerate(usage_list)):\n",
        "            feat = load_feat(os.path.join(feat_dir, mode, f'{fname}.pt'))\n",
        "            cur_len = len(feat)\n",
        "            feat = concat_feat(feat, concat_nframes)\n",
        "            if mode == 'train':\n",
        "                label = torch.LongTensor(label_dict[fname])\n",
        "\n",
        "            X[idx: idx + cur_len, :] = feat\n",
        "            if mode == 'train':\n",
        "                y[idx: idx + cur_len] = label\n",
        "\n",
        "            idx += cur_len\n",
        "\n",
        "        X = X[:idx, :]\n",
        "        if mode == 'train':\n",
        "            y = y[:idx]\n",
        "\n",
        "        print(f'[INFO] {split} set')\n",
        "        print(X.shape)\n",
        "        if mode == 'train':\n",
        "            print(y.shape)\n",
        "            return X, y\n",
        "        else:\n",
        "            return X\n",
        "    \n",
        "    if mode == 'test':\n",
        "        return transform_data(test_list, \"test\")\n",
        "    \n",
        "    return *transform_data(train_list, \"train\"), *transform_data(val_list, \"val\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "us5XW_x6udZQ"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Fjf5EcmJtf4e"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class LibriDataset(Dataset):\n",
        "    def __init__(self, X, y=None):\n",
        "        self.data = X\n",
        "        if y is not None:\n",
        "            self.label = torch.LongTensor(y)\n",
        "        else:\n",
        "            self.label = None\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.label is not None:\n",
        "            return self.data[idx], self.label[idx]\n",
        "        else:\n",
        "            return self.data[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRqKNvNZwe3V"
      },
      "source": [
        "# Model\n",
        "Feel free to modify the structure of the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Bg-GRd7ywdrL"
      },
      "outputs": [],
      "source": [
        "# import torch.nn as nn\n",
        "\n",
        "# class BasicBlock(nn.Module):\n",
        "#     def __init__(self, input_dim, output_dim):\n",
        "#         super(BasicBlock, self).__init__()\n",
        "\n",
        "#         # TODO: apply batch normalization and dropout for strong baseline.\n",
        "#         # Reference: https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html (batch normalization)\n",
        "#         #       https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html (dropout)\n",
        "#         self.block = nn.Sequential(\n",
        "#             nn.Linear(input_dim, output_dim),\n",
        "#             nn.BatchNorm1d(output_dim),\n",
        "#             nn.ReLU(),\n",
        "#             nn.Dropout(0.3),\n",
        "#         )\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = self.block(x)\n",
        "#         return x\n",
        "\n",
        "\n",
        "# class Classifier(nn.Module):\n",
        "#     def __init__(self, input_dim, output_dim=41, hidden_layers=1, hidden_dim=256):\n",
        "#         super(Classifier, self).__init__()\n",
        "\n",
        "#         self.fc = nn.Sequential(\n",
        "#             BasicBlock(input_dim, hidden_dim),\n",
        "#             *[BasicBlock(hidden_dim, hidden_dim) for _ in range(hidden_layers)],\n",
        "#             nn.Linear(hidden_dim, output_dim)\n",
        "#         )\n",
        "        \n",
        "#         self.emb = nn.Embedding(input_dim, embedding_dim=hidden_dim)\n",
        "#         self.rnn = nn.RNN(hidden_dim, hidden_dim, num_layers=1)\n",
        "#         self.linear = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "#         # self.rnn = nn.Sequential(\n",
        "#         #     nn.Embedding(input_dim, embedding_dim=hidden_dim),\n",
        "#         #     nn.RNN(hidden_dim, hidden_dim, num_layers=1),\n",
        "#         #     nn.Linear(hidden_dim, output_dim),\n",
        "#         # )\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         # x = self.fc(x)\n",
        "#         x = self.rnn(x)\n",
        "#         print(x.shape())\n",
        "#         return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlIq8JeqvvHC"
      },
      "source": [
        "# Hyper-parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "iIHn79Iav1ri"
      },
      "outputs": [],
      "source": [
        "# data prarameters\n",
        "# TODO: change the value of \"concat_nframes\" for medium baseline\n",
        "concat_nframes = 85   # the number of frames to concat with, n must be odd (total 2k+1 = n frames)\n",
        "train_ratio = 0.95   # the ratio of data used for training, the rest will be used for validation\n",
        "\n",
        "# training parameters\n",
        "seed = 1213          # random seed\n",
        "batch_size = 512        # batch size\n",
        "num_epoch = 30         # the number of training epoch\n",
        "learning_rate = 1e-4      # learning rate\n",
        "model_path = './model.ckpt'  # the path where the checkpoint will be saved\n",
        "\n",
        "# model parameters\n",
        "# TODO: change the value of \"hidden_layers\" or \"hidden_dim\" for medium baseline\n",
        "input_dim = 39 * concat_nframes  # the input dim of the model, you should not change the value\n",
        "hidden_layers = 6          # the number of hidden layers\n",
        "hidden_dim = 600           # the hidden dim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIUFRgG5yoDn"
      },
      "source": [
        "# Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "c1zI3v5jyrDn"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEVICE: cuda\n",
            "[Dataset] - # phone classes: 41, number of utterances for train: 3257\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "0it [00:00, ?it/s]/tmp/ipykernel_544156/449328754.py:100: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  feat = torch.load(path)\n",
            "3257it [00:37, 87.60it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] train set\n",
            "torch.Size([2007632, 3315])\n",
            "torch.Size([2007632])\n",
            "[Dataset] - # phone classes: 41, number of utterances for val: 172\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "172it [00:02, 60.86it/s] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] val set\n",
            "torch.Size([109162, 3315])\n",
            "torch.Size([109162])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "import gc\n",
        "\n",
        "same_seeds(seed)\n",
        "torch.cuda.set_device(\"cuda:7\")\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f'DEVICE: {device}')\n",
        "\n",
        "# # preprocess data\n",
        "# train_X, train_y = preprocess_data(split='train', feat_dir='./libriphone/feat', phone_path='./libriphone', concat_nframes=concat_nframes, train_ratio=train_ratio)\n",
        "# val_X, val_y = preprocess_data(split='val', feat_dir='./libriphone/feat', phone_path='./libriphone', concat_nframes=concat_nframes, train_ratio=train_ratio)\n",
        "train_X, train_y, val_X, val_y = preprocess_data(split='train', feat_dir='./libriphone/feat', phone_path='./libriphone', concat_nframes=concat_nframes, train_ratio=train_ratio)\n",
        "\n",
        "\n",
        "# get dataset\n",
        "train_set = LibriDataset(train_X, train_y)\n",
        "val_set = LibriDataset(val_X, val_y)\n",
        "\n",
        "# remove raw feature to save memory\n",
        "del train_X, train_y, val_X, val_y\n",
        "gc.collect()\n",
        "\n",
        "# get dataloader\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwWH1KIqzxEr"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # data prarameters\n",
        "# # TODO: change the value of \"concat_nframes\" for medium baseline\n",
        "# concat_nframes = 25   # the number of frames to concat with, n must be odd (total 2k+1 = n frames)\n",
        "# train_ratio = 0.75   # the ratio of data used for training, the rest will be used for validation\n",
        "\n",
        "# # training parameters\n",
        "# seed = 1213          # random seed\n",
        "# batch_size = 512        # batch size\n",
        "# num_epoch = 30         # the number of training epoch\n",
        "# learning_rate = 1e-4      # learning rate\n",
        "# model_path = './model.ckpt'  # the path where the checkpoint will be saved\n",
        "\n",
        "# # model parameters\n",
        "# # TODO: change the value of \"hidden_layers\" or \"hidden_dim\" for medium baseline\n",
        "# input_dim = 39 * concat_nframes  # the input dim of the model, you should not change the value\n",
        "# hidden_layers = 3          # the number of hidden layers\n",
        "# hidden_dim = 1024           # the hidden dim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(BasicBlock, self).__init__()\n",
        "\n",
        "        # TODO: apply batch normalization and dropout for strong baseline.\n",
        "        # Reference: https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html (batch normalization)\n",
        "        #       https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html (dropout)\n",
        "        self.block = nn.Sequential(\n",
        "            nn.Linear(input_dim, output_dim),\n",
        "            nn.BatchNorm1d(output_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.block(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim=41, hidden_layers=1, hidden_dim=256):\n",
        "        super(Classifier, self).__init__()\n",
        "\n",
        "        # # fc fully connected\n",
        "        # self.fc = nn.Sequential(\n",
        "        #     BasicBlock(input_dim, hidden_dim),\n",
        "        #     # * 解包操作符，例如*args，等同于手动输入列表中的元素，去掉列表的框\n",
        "        #     *[BasicBlock(hidden_dim, hidden_dim) for _ in range(hidden_layers)],\n",
        "        #     nn.Linear(hidden_dim, output_dim)\n",
        "        # )\n",
        "        self.rnn = nn.LSTM(39, hidden_dim, num_layers=hidden_layers, batch_first=True, bidirectional=True, dropout=0.5)\n",
        "        # 用bidiretional维度会翻倍，这是初版输出层，用了biLSTM输出的所有信息\n",
        "        # self.linear = nn.Linear(input_dim//39 * hidden_dim * 2, output_dim)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(hidden_dim * 2, hidden_dim//2),\n",
        "            nn.BatchNorm1d(hidden_dim//2),\n",
        "            nn.ReLU(),\n",
        "            #作为LSTM的全连接层时，层数调小，dropout也调小\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(hidden_dim//2, output_dim),\n",
        "        )\n",
        "        # self.rnn = nn.Sequential(\n",
        "        #     #nn.Embedding(input_dim, embedding_dim=hidden_dim),\n",
        "        #     nn.RNN(input_dim, hidden_dim, num_layers=1),\n",
        "        #     nn.Linear(hidden_dim, output_dim),\n",
        "        # )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x = self.fc(x)\n",
        "        batch_size, x_input = x.shape\n",
        "        x, _ = self.rnn(x.view(batch_size,-1,39))\n",
        "        # x = self.fc(x.reshape(batch_size, -1))\n",
        "        #只取x的最后一个时间步作为fc的输入,注意正向和反向数据的位置\n",
        "        x = x[:,input_dim//78]\n",
        "        # print(x.shape)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "CdMWsBs7zzNs"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3922/3922 [15:52<00:00,  4.12it/s]\n",
            "100%|██████████| 214/214 [00:16<00:00, 13.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[001/030] Train Acc: 0.75314 Loss: 0.81794 | Val Acc: 0.80078 loss: 0.65145\n",
            "saving model with acc 0.80078\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3922/3922 [15:52<00:00,  4.12it/s]\n",
            "100%|██████████| 214/214 [00:16<00:00, 13.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[002/030] Train Acc: 0.87874 Loss: 0.36299 | Val Acc: 0.81543 loss: 0.66507\n",
            "saving model with acc 0.81543\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3922/3922 [15:51<00:00,  4.12it/s]\n",
            "100%|██████████| 214/214 [00:16<00:00, 13.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[003/030] Train Acc: 0.91510 Loss: 0.23715 | Val Acc: 0.82332 loss: 0.68647\n",
            "saving model with acc 0.82332\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3922/3922 [15:51<00:00,  4.12it/s]\n",
            "100%|██████████| 214/214 [00:16<00:00, 13.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[004/030] Train Acc: 0.93174 Loss: 0.18297 | Val Acc: 0.82437 loss: 0.74961\n",
            "saving model with acc 0.82437\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3922/3922 [15:51<00:00,  4.12it/s]\n",
            "100%|██████████| 214/214 [00:16<00:00, 13.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[005/030] Train Acc: 0.94149 Loss: 0.15250 | Val Acc: 0.82629 loss: 0.76787\n",
            "saving model with acc 0.82629\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3922/3922 [15:53<00:00,  4.11it/s]\n",
            "100%|██████████| 214/214 [00:16<00:00, 12.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[006/030] Train Acc: 0.94820 Loss: 0.13236 | Val Acc: 0.82926 loss: 0.77711\n",
            "saving model with acc 0.82926\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3922/3922 [15:53<00:00,  4.11it/s]\n",
            "100%|██████████| 214/214 [00:16<00:00, 13.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[007/030] Train Acc: 0.95341 Loss: 0.11785 | Val Acc: 0.82733 loss: 0.82624\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3922/3922 [15:52<00:00,  4.12it/s]\n",
            "100%|██████████| 214/214 [00:16<00:00, 12.98it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[008/030] Train Acc: 0.95715 Loss: 0.10711 | Val Acc: 0.83305 loss: 0.83133\n",
            "saving model with acc 0.83305\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3922/3922 [15:52<00:00,  4.12it/s]\n",
            "100%|██████████| 214/214 [00:16<00:00, 13.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[009/030] Train Acc: 0.96059 Loss: 0.09811 | Val Acc: 0.83487 loss: 0.85115\n",
            "saving model with acc 0.83487\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3922/3922 [15:56<00:00,  4.10it/s]\n",
            "100%|██████████| 214/214 [00:16<00:00, 13.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[010/030] Train Acc: 0.96354 Loss: 0.09081 | Val Acc: 0.83439 loss: 0.87638\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3922/3922 [15:58<00:00,  4.09it/s]\n",
            "100%|██████████| 214/214 [00:16<00:00, 12.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[011/030] Train Acc: 0.96605 Loss: 0.08459 | Val Acc: 0.83560 loss: 0.88942\n",
            "saving model with acc 0.83560\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3922/3922 [15:55<00:00,  4.10it/s]\n",
            "100%|██████████| 214/214 [00:16<00:00, 13.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[012/030] Train Acc: 0.96818 Loss: 0.07898 | Val Acc: 0.83627 loss: 0.89195\n",
            "saving model with acc 0.83627\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3922/3922 [15:56<00:00,  4.10it/s]\n",
            "100%|██████████| 214/214 [00:16<00:00, 12.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[013/030] Train Acc: 0.97014 Loss: 0.07429 | Val Acc: 0.83892 loss: 0.91364\n",
            "saving model with acc 0.83892\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3922/3922 [15:56<00:00,  4.10it/s]\n",
            "100%|██████████| 214/214 [00:16<00:00, 12.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[014/030] Train Acc: 0.97190 Loss: 0.07016 | Val Acc: 0.83636 loss: 0.95674\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3922/3922 [15:58<00:00,  4.09it/s]\n",
            "100%|██████████| 214/214 [00:16<00:00, 13.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[015/030] Train Acc: 0.97347 Loss: 0.06646 | Val Acc: 0.83588 loss: 0.97268\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3922/3922 [16:00<00:00,  4.08it/s]\n",
            "100%|██████████| 214/214 [00:16<00:00, 12.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[016/030] Train Acc: 0.97460 Loss: 0.06346 | Val Acc: 0.83824 loss: 0.96680\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3922/3922 [16:04<00:00,  4.07it/s]\n",
            "100%|██████████| 214/214 [00:16<00:00, 12.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[017/030] Train Acc: 0.97609 Loss: 0.06015 | Val Acc: 0.83873 loss: 0.96445\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3922/3922 [16:03<00:00,  4.07it/s]\n",
            "100%|██████████| 214/214 [00:16<00:00, 12.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[018/030] Train Acc: 0.97722 Loss: 0.05730 | Val Acc: 0.83580 loss: 1.03290\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3922/3922 [16:03<00:00,  4.07it/s]\n",
            "100%|██████████| 214/214 [00:16<00:00, 12.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[019/030] Train Acc: 0.97813 Loss: 0.05504 | Val Acc: 0.83913 loss: 1.00543\n",
            "saving model with acc 0.83913\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3922/3922 [16:04<00:00,  4.07it/s]\n",
            "100%|██████████| 214/214 [00:16<00:00, 12.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[020/030] Train Acc: 0.97913 Loss: 0.05278 | Val Acc: 0.83922 loss: 1.03282\n",
            "saving model with acc 0.83922\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3922/3922 [16:04<00:00,  4.07it/s]\n",
            "100%|██████████| 214/214 [00:16<00:00, 12.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[021/030] Train Acc: 0.98004 Loss: 0.05046 | Val Acc: 0.83611 loss: 1.06222\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3922/3922 [16:03<00:00,  4.07it/s]\n",
            "100%|██████████| 214/214 [00:16<00:00, 12.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[022/030] Train Acc: 0.98062 Loss: 0.04909 | Val Acc: 0.83690 loss: 1.07023\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3922/3922 [15:57<00:00,  4.09it/s]\n",
            "100%|██████████| 214/214 [00:16<00:00, 12.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[023/030] Train Acc: 0.98132 Loss: 0.04731 | Val Acc: 0.83846 loss: 1.06748\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3922/3922 [15:54<00:00,  4.11it/s]\n",
            "100%|██████████| 214/214 [00:16<00:00, 12.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[024/030] Train Acc: 0.98213 Loss: 0.04564 | Val Acc: 0.83960 loss: 1.07481\n",
            "saving model with acc 0.83960\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3922/3922 [15:55<00:00,  4.11it/s]\n",
            "100%|██████████| 214/214 [00:16<00:00, 13.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[025/030] Train Acc: 0.98268 Loss: 0.04421 | Val Acc: 0.84055 loss: 1.08967\n",
            "saving model with acc 0.84055\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3922/3922 [15:55<00:00,  4.11it/s]\n",
            "100%|██████████| 214/214 [00:16<00:00, 13.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[026/030] Train Acc: 0.98338 Loss: 0.04249 | Val Acc: 0.84212 loss: 1.11719\n",
            "saving model with acc 0.84212\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3922/3922 [15:55<00:00,  4.11it/s]\n",
            "100%|██████████| 214/214 [00:16<00:00, 12.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[027/030] Train Acc: 0.98373 Loss: 0.04167 | Val Acc: 0.84329 loss: 1.10279\n",
            "saving model with acc 0.84329\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3922/3922 [15:55<00:00,  4.10it/s]\n",
            "100%|██████████| 214/214 [00:16<00:00, 12.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[028/030] Train Acc: 0.98415 Loss: 0.04053 | Val Acc: 0.84180 loss: 1.11270\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3922/3922 [15:55<00:00,  4.11it/s]\n",
            "100%|██████████| 214/214 [00:16<00:00, 13.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[029/030] Train Acc: 0.98481 Loss: 0.03930 | Val Acc: 0.83936 loss: 1.12358\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3922/3922 [15:50<00:00,  4.13it/s]\n",
            "100%|██████████| 214/214 [00:16<00:00, 12.97it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[030/030] Train Acc: 0.98518 Loss: 0.03822 | Val Acc: 0.84021 loss: 1.14847\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# create model, define a loss function, and optimizer\n",
        "model = Classifier(input_dim=input_dim, hidden_layers=hidden_layers, hidden_dim=hidden_dim).to(device)\n",
        "#已经训练30轮\n",
        "# model.load_state_dict(torch.load(model_path))\n",
        "criterion = nn.CrossEntropyLoss() \n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "best_acc = 0.0\n",
        "for epoch in range(num_epoch):\n",
        "    train_acc = 0.0\n",
        "    train_loss = 0.0\n",
        "    val_acc = 0.0\n",
        "    val_loss = 0.0\n",
        "    \n",
        "    # training\n",
        "    model.train() # set the model to training mode\n",
        "    for i, batch in enumerate(tqdm(train_loader)):\n",
        "        features, labels = batch\n",
        "        features = features.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        optimizer.zero_grad() \n",
        "        outputs = model(features) \n",
        "        \n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward() \n",
        "        optimizer.step() \n",
        "        \n",
        "        _, train_pred = torch.max(outputs, 1) # get the index of the class with the highest probability\n",
        "        train_acc += (train_pred.detach() == labels.detach()).sum().item()\n",
        "        train_loss += loss.item()\n",
        "    \n",
        "    # validation\n",
        "    model.eval() # set the model to evaluation mode\n",
        "    with torch.no_grad():\n",
        "        for i, batch in enumerate(tqdm(val_loader)):\n",
        "            features, labels = batch\n",
        "            features = features.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(features)\n",
        "            \n",
        "            loss = criterion(outputs, labels) \n",
        "            \n",
        "            _, val_pred = torch.max(outputs, 1) \n",
        "            val_acc += (val_pred.cpu() == labels.cpu()).sum().item() # get the index of the class with the highest probability\n",
        "            val_loss += loss.item()\n",
        "\n",
        "    print(f'[{epoch+1:03d}/{num_epoch:03d}] Train Acc: {train_acc/len(train_set):3.5f} Loss: {train_loss/len(train_loader):3.5f} | Val Acc: {val_acc/len(val_set):3.5f} loss: {val_loss/len(val_loader):3.5f}')\n",
        "\n",
        "    # if the model improves, save a checkpoint at this epoch\n",
        "    if val_acc > best_acc:\n",
        "        best_acc = val_acc\n",
        "        torch.save(model.state_dict(), model_path)\n",
        "        print(f'saving model with acc {best_acc/len(val_set):.5f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ab33MxosWLmG"
      },
      "outputs": [],
      "source": [
        "# del train_set, val_set\n",
        "# del train_loader, val_loader\n",
        "# gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Hi7jTn3PX-m"
      },
      "source": [
        "# Testing\n",
        "Create a testing dataset, and load model from the saved checkpoint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "VOG1Ou0PGrhc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Dataset] - # phone classes: 41, number of utterances for test: 857\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "0it [00:00, ?it/s]/tmp/ipykernel_544156/449328754.py:100: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  feat = torch.load(path)\n",
            "857it [00:24, 35.47it/s] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] test set\n",
            "torch.Size([527364, 3315])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# load data\n",
        "test_X = preprocess_data(split='test', feat_dir='./libriphone/feat', phone_path='./libriphone', concat_nframes=concat_nframes)\n",
        "test_set = LibriDataset(test_X, None)\n",
        "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ay0Fu8Ovkdad"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_544156/3352857437.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path))\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# load model\n",
        "model = Classifier(input_dim=input_dim, hidden_layers=hidden_layers, hidden_dim=hidden_dim).to(device)\n",
        "model.load_state_dict(torch.load(model_path))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zp-DV1p4r7Nz"
      },
      "source": [
        "Make prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "84HU5GGjPqR0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1031/1031 [01:16<00:00, 13.48it/s]\n"
          ]
        }
      ],
      "source": [
        "pred = np.array([], dtype=np.int32)\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for i, batch in enumerate(tqdm(test_loader)):\n",
        "        features = batch\n",
        "        features = features.to(device)\n",
        "\n",
        "        outputs = model(features)\n",
        "\n",
        "        _, test_pred = torch.max(outputs, 1) # get the index of the class with the highest probability\n",
        "        pred = np.concatenate((pred, test_pred.cpu().numpy()), axis=0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyZqy40Prz0v"
      },
      "source": [
        "Write prediction to a CSV file.\n",
        "\n",
        "After finish running this block, download the file `prediction.csv` from the files section on the left-hand side and submit it to Kaggle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "GuljYSPHcZir"
      },
      "outputs": [],
      "source": [
        "with open('prediction.csv', 'w') as f:\n",
        "    f.write('Id,Class\\n')\n",
        "    for i, y in enumerate(pred):\n",
        "        f.write('{},{}\\n'.format(i, y))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "lhy",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
